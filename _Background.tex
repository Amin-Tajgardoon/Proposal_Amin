\chapter{Background}

% \section{Structured EHR Data Representation Learning}
% Structured data is referred to tabular data with columns and rows where each column represents a variable and each row represents a data instance or sample. Certain representation learning (RL) methods assume that the input data is in a structured format. EHR data in general is multimodal data consists of structured tables, images, and clinical notes in text format. In this section, we focus on the structured EHR tables and overview the RL methods suitable for such data format.

\section{Neural Network-based Representation Learning Methods}

An artificial neural network (ANN) consists of multiple inter-connected layers where each layer includes several computing \textit{units}. The first and last layers correspond to the input and output layers, respectively; the layers in between are called \textit{hidden layers}. Each unit in a hidden layer has a continuous weight parameter that is optimized for a specific task such as a supervised classification or unsupervised clustering. It has been shown that the hidden layers learn dense and low-dimensional representations of the input that are linked to the superior performance of the ANNs in solving certain problems \cite{bengio2013representation}. This property has lead to the use ANNs for the task of learning better data representations; that is, inputting the data into a multilayer ANN, estimate the unit parameters for a specific task, and use a hidden layer as the learned representation of the data.

Another advantage of ANNs is that they can handle different data modes by employing the appropriate network architecture. For example, the convolutional neural network (CNN) architecture \cite{lecun1998gradient} is used for processing image data, recurrent neural network (RNN) architecture \cite{hochreiter1997long} is appropriate for sequence data such as text or time-series data, and multilayer perceptrons (MLP) architecture is suitable for structured tabular data. Furthermore, different ANN architectures can be integrated in order to process multimodal data where several data modes are input to the same ANN. Therefore, using ANNs unified representations can be learned from multimodal data.

The recent success of ANNs and deep learning methods in computer vision and natural language processing (NLP) has encouraged the researchers to adapt these approaches for clinical data such as electronic health records (EHR) \cite{Xiao2018}. There are various representation learning methods that are based on ANNs and have been applied to clinical data. In the following sections we discuss these methods with examples of their application in clinical modeling.

\subsection{Encoder-decoder based Methods}
Encoder-decoder (ED) is a general framework for learning a latent representation of the data \cite{Hinton2006}. Encoder is a function that maps the input to a latent space and decoder is a function that does the opposite; that is, maps the input from latent space to the original space. The optimization objective in an ED framework is to minimize the reconstruction error, i.e., to minimize the difference between the decoder's output and the encoder's input. The latent space is used as a continuous and low-dimensional representation of the sparse categorical input data.

Multilayer ANNs are used to implement ED as autoencoders (AE) where the input and output layers represent encoder and encoder components, respectively, and the latent representation is learned in the hidden layers \cite{Hinton2006, Vincent2008}. Various AE architectures have been proposed such as sparse autoencoders (SAE) where a penalty is used to enforce a fraction of units in the hidden layer to be zero. Another common type is denoising autoencoders (DAE) in which some noise is introduced in the input in order to make the AE robust to corrupted data. Representation learning using AE is often unsupervised, i.e., there are no external labels are required for the task. The learned representation, however, can be used as input to downstream supervised tasks.

Another class of ED based methods are transformer networks introduced by \cite{Vaswani2017transformers} which consists of one block of encoder and one block of decoder. Each block contains multiple identical stacked encoders or decoders. Each encoder unit has a layer of multi-head attention followed by a feed forward ANN layer. A decoder unit has an additional layer of masked multi-head attention. Because of the multi-head attention layers and  the self-attention mechanism that they provide, unlike RNNs, transformers do not need the input sequence to be ordered. Since their introduction, transformers have been the state-of-the-art method in the NLP domain.

% Representation learning using AE can be grouped into unsupervised or supervised categories. In unsupervised methods, the optimization goal is to minimize the reconstruction error and external labels are not required. In contrast, in supervised methods the the decoder component is extended for minimizing a supervised loss function such as in a classification task and the learned representation is biased to the supervised task at hand.

EHR data consists of thousands of medical codes and using these codes as features in machine learning creates a sparse input matrix with categorical values. A large sparse matrix does not contain useful information about the relations among features and can slow down the model training process. The ED framework has been applied to EHR data to learn useful input representation that can improve the performance of down stream machine learning tasks \cite{Weng2019}. Table\ref{tab:RL_AE} shows a list of recent papers that have used an ED framework for representation learning in the clinical domain.

\input{tables/tab_RL_AE}

\subsection{Word2vec based Methods}
\textit{Word2vec} is a representation learning method proposed by \cite{mikolov2013efficient} for machine learning models in the natural language processing (NLP) domain. In contrast to the simple one-hot code representation of words that is very sparse and does not include any information about the relationships between words in a document, word2vec algorithms learn a compact and low-dimensional projection such that similar words are closer together. Two popular word2vec algorithms are \textit{skip-gram} and \textit{continuous bag-of-words} (CBOW). Skip-gram is an unsupervised algorithm that learns the words representations based on the co-occurrence matrix of words within a predefined context window. Given a target word, the task in skip-gram is to predict the neighboring words. Conversely, the task in CBOW is to predict the target word given its neighbors within a window context. Similar to autoencoders, each word's representation is a continuous vector that is learned as a hidden layer in an ANN.

EHR data consists of many medical codes that can be considered as bag of words. Using word2vec algorithms, meaningful representations can be learned for medical codes; for example, similar diseases would be closer in the new latent space, or similar medications can be grouped together. Moreover, treating EHR data as a collection of words facilitates the use of clinical notes in the EHR along with the structured data in machine learning applications. Many researchers have applied the word2vec method to clinical data in order to obtain compact representations of medical concepts which provide more insight about the data and also can improve the performance of diagnostic and prognostic models \cite{Weng2019}. Table\ref{tab:RL_W2V} lists a number of recent papers where word2vec method has been successfully been applied to clinical data.

\input{tables/tab_RL_W2V}


\subsection{Transfer Learning based Methods}
Transfer learning in machine learning is a method to transfer knowledge from a source domain with abundant data to a target domain with smaller data \cite{tan2018TLsurvey}. For example, weights from a deep image classifier that is trained on a large set of dog images can be used as initial weights in another deep image classifier for a smaller set of cat images; the assumption is that the dog image classifier learns some high level representations that can also be useful in classifying cat images. The idea of transfer learning has been used in computer vision for a number of years \cite{krizhevsky2012imagenet}. In NLP domain the idea has become more popular recently with the introduction of methods like \textit{embeddings from language model} (ELMo) \cite{peters2018deep},  \textit{universal language model fine tuning} ULMFiT \cite{howard2018universal}, and \textit{bidirectional encoder representations from Transformers} BERT \cite{devlin2018bert}.

Similar to the NLP domain, there are lots of unlabeled data in the clinical domain that can be used to learn high level representations in an unsupervised manner and applying them in problems with smaller available data. Researchers have pre-trained unsupervised ANN models on large sets of text from biomedical literature and EHR notes to capture a general knowledge from the domain that can help improving smaller and more specific tasks \cite{Dubois2018, Lee2020}. Table \ref{tab:RL_TL} contains examples of projects that have used transfer learning in the clinical domain.

\input{tables/tab_RL_TL}

\subsection{End-to-end Methods}
ANNs receive the raw input at the input layer and pass it to the output through one or more intermediate hidden layers. It has been shown that higher level and abstract representation of the raw input are learned in the hidden layers \cite{lecun2015deep}. For example, an ANN used for face recognition receives the image pixels at the input layer and learns abstract representations such as edge arrangements or face parts in the hidden layers. The representation learned at the hidden layers is a non-linear projection of the raw pixels that is easier to classify at the output layer. 

This property of the ANNs has attracted researchers in the clinical domain to use these models as an end-to-end solution for various tasks such as clinical event prediction and patient phenotyping \cite{AyalaSolares2020deep_survey}, where different mechanisms such as attention, convolution layer, or gated recurrent unit (GRU) has been used at the hidden layers for a more meaningful representation or even an improvement in the interpretability of the model \cite{Mullenbach2018Explainable}. The representation learned by an end-to-end method is usually task-specific, although it can be re-used or fine-tuned in a similar task using transfer learning methods. A number of example projects are listed in Table \ref{tab:RL_E2E} that have used different ANN architectures or attention mechanism to approach clinical tasks.

\input{tables/tab_RL_E2E}

% \subsection{Graph based Methods}